{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, FixedThresholdClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedData = pd.read_csv('../Fully-Cleaned-Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalColumns = cleanedData.select_dtypes(include=['object']).columns.tolist()\n",
    "numericalData = cleanedData.drop(columns=categoricalColumns)\n",
    "oneHotData = pd.get_dummies(cleanedData[categoricalColumns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanedDataOneHotEncoded = pd.concat([numericalData, oneHotData], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cleanedDataOneHotEncoded.drop(['Future Relapse Binary'], axis=1)\n",
    "y = cleanedDataOneHotEncoded['Future Relapse Binary']\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
    "\n",
    "def print_scoring_metrics(fittedModel, return_scores = False):\n",
    "    train_preds = fittedModel.predict(XTrain)\n",
    "    train_proba_preds = fittedModel.predict_proba(XTrain)[:, 1]\n",
    "    test_preds = fittedModel.predict(XTest)\n",
    "    test_proba_preds = fittedModel.predict_proba(XTest)[:, 1]\n",
    "    print('Training Scores')\n",
    "    print(f'Accuracy: {accuracy_score(yTrain, train_preds)}')\n",
    "    print(f'Recall: {recall_score(yTrain, train_preds)}')\n",
    "    print(f'Specificity: {recall_score(yTrain, train_preds, pos_label=0)}')\n",
    "    print(f'Precision: {precision_score(yTrain, train_preds)}')\n",
    "    print(f'F1: {f1_score(yTrain, train_preds)}')\n",
    "    print(f'ROC AUC: {roc_auc_score(yTrain, train_proba_preds)}')\n",
    "    print('--------------------------------')\n",
    "    print('Test Scores')\n",
    "    print(f'Accuracy: {accuracy_score(yTest, test_preds)}')\n",
    "    print(f'Recall: {recall_score(yTest, test_preds)}')\n",
    "    print(f'Specificity: {recall_score(yTest, test_preds, pos_label=0)}')\n",
    "    print(f'Precision: {precision_score(yTest, test_preds)}')\n",
    "    print(f'F1: {f1_score(yTest, test_preds)}')\n",
    "    print(f'ROC AUC: {roc_auc_score(yTest, test_proba_preds)}')\n",
    "    if return_scores:\n",
    "        return f'{accuracy_score(yTest, test_preds):.4f}\\t{recall_score(yTest, test_preds):.4f}\\t{recall_score(yTest, test_preds, pos_label=0):.4f}\\t{precision_score(yTest, test_preds):.4f}\\t{f1_score(yTest, test_preds):.4f}\\t{roc_auc_score(yTest, test_proba_preds):.4f}'\n",
    "    else:\n",
    "        print(f'{accuracy_score(yTest, test_preds):.4f}\\t{recall_score(yTest, test_preds):.4f}\\t{recall_score(yTest, test_preds, pos_label=0):.4f}\\t{precision_score(yTest, test_preds):.4f}\\t{f1_score(yTest, test_preds):.4f}\\t{roc_auc_score(yTest, test_proba_preds):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "cross_validation_scoring = {\n",
    "    'acc': 'accuracy', \n",
    "    'rec': 'recall', \n",
    "    'spec': make_scorer(recall_score, pos_label=0), \n",
    "    'prec': 'precision',\n",
    "    'f1_score': 'f1', \n",
    "    'auc': 'roc_auc'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.frozen import FrozenEstimator\n",
    "\n",
    "def cross_validated_threshold(fittedModel, new_threshold):\n",
    "    tuned_threshold_model = FixedThresholdClassifier(\n",
    "        estimator = FrozenEstimator(fittedModel),\n",
    "        threshold = new_threshold\n",
    "    )\n",
    "\n",
    "    cv_results = cross_validate(tuned_threshold_model, X, y, cv=10, scoring=cross_validation_scoring)\n",
    "    \n",
    "    return tuned_threshold_model, cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_recall_threshold(fittedModel):\n",
    "    results_dict = {}\n",
    "    #recall_dict = {}\n",
    "    for threshold in np.linspace(0, 1, 99):\n",
    "        # new_threshold_model = FixedThresholdClassifier(\n",
    "        #     estimator = FrozenEstimator(fittedModel), \n",
    "        #     threshold = threshold\n",
    "        # )\n",
    "        tuned_threshold_model, cv_results = cross_validated_threshold(fittedModel, threshold)\n",
    "        print(np.average(cv_results['test_rec']))\n",
    "        if np.abs(np.average(cv_results['test_rec']) - 80) < 2:\n",
    "            print(cv_results)\n",
    "            results_dict[threshold] = print_scoring_metrics(tuned_threshold_model, True)\n",
    "\n",
    "    print(results_dict)\n",
    "\n",
    "        #y_hat = new_threshold_model.predict(XTest)\n",
    "        #calculated_recall_score = recall_score(yTest, y_hat)\n",
    "        #if calculated_recall_score > 0.78 and calculated_recall_score < 0.82:\n",
    "        #    results_dict['accuracy'].append(accuracy_score(yTest, y_hat))\n",
    "            #recall_dict[threshold] = calculated_recall_score\n",
    "    #recall_dict_value_sorted = dict(sorted(recall_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "    #print(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def using_recall_threshold(fittedModel, new_threshold):\n",
    "    tuned_threshold_model = FixedThresholdClassifier(\n",
    "        estimator = FrozenEstimator(fittedModel),\n",
    "        threshold = new_threshold\n",
    "    ).fit(XTrain, yTrain)\n",
    "    print_scoring_metrics(tuned_threshold_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "cross_validation_scoring = {\n",
    "    'acc': 'accuracy', \n",
    "    'rec': 'recall', \n",
    "    'spec': make_scorer(recall_score, pos_label=0), \n",
    "    'prec': 'precision',\n",
    "    'f1_score': 'f1', \n",
    "    'auc': 'roc_auc'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def cross_validated_threshold(fittedModel, new_threshold):\n",
    "    tuned_threshold_model = FixedThresholdClassifier(\n",
    "        estimator = FrozenEstimator(fittedModel),\n",
    "        threshold = new_threshold\n",
    "    )\n",
    "\n",
    "    cv_results = cross_validate(tuned_threshold_model, XTrain, yTrain, cv=10, scoring=cross_validation_scoring)\n",
    "\n",
    "    return cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "\n",
    "criterion: entropy, max_depth: 8, max_features: sqrt, min_samples_split: 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(\n",
    "    class_weight='balanced',\n",
    "    max_depth=8,\n",
    "    max_features='sqrt',\n",
    "    min_samples_split=9,\n",
    "    criterion='entropy'\n",
    ").fit(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores\n",
      "Accuracy: 0.6742671009771987\n",
      "Recall: 0.6575591985428051\n",
      "Specificity: 0.6835699797160243\n",
      "Precision: 0.5364041604754829\n",
      "F1: 0.5908346972176759\n",
      "ROC AUC: 0.7536559187458665\n",
      "--------------------------------\n",
      "Test Scores\n",
      "Accuracy: 0.578125\n",
      "Recall: 0.44808743169398907\n",
      "Specificity: 0.6504559270516718\n",
      "Precision: 0.41624365482233505\n",
      "F1: 0.43157894736842106\n",
      "ROC AUC: 0.5612304217117611\n",
      "0.5781\t0.4481\t0.6505\t0.4162\t0.4316\t0.5612\n"
     ]
    }
   ],
   "source": [
    "print_scoring_metrics(decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5612304217117611\n"
     ]
    }
   ],
   "source": [
    "print(roc_auc_score(yTest, decision_tree.predict_proba(XTest)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9781192151055166\n",
      "0.9781192151055166\n",
      "0.9781192151055166\n",
      "0.9781192151055166\n",
      "0.9781192151055166\n",
      "0.9781192151055166\n",
      "0.9781192151055166\n",
      "0.9740096260644207\n",
      "0.9740096260644207\n",
      "0.9740096260644207\n",
      "0.972639763050722\n",
      "0.9699000370233248\n",
      "0.9671603109959275\n",
      "0.9671603109959275\n",
      "0.9671603109959275\n",
      "0.9671603109959275\n",
      "0.9671603109959275\n",
      "0.9671603109959275\n",
      "0.9671603109959275\n",
      "0.9671603109959275\n",
      "0.9657904479822289\n",
      "0.9657904479822289\n",
      "0.9603295075897818\n",
      "0.9603295075897818\n",
      "0.9603295075897818\n",
      "0.958959644576083\n",
      "0.958959644576083\n",
      "0.958959644576083\n",
      "0.958959644576083\n",
      "0.958959644576083\n",
      "0.9548500555349871\n",
      "0.9466308774527953\n",
      "0.9466308774527953\n",
      "0.9466308774527953\n",
      "0.9466308774527953\n",
      "0.9466308774527953\n",
      "0.9425398000740467\n",
      "0.9425398000740467\n",
      "0.9425398000740467\n",
      "0.9425398000740467\n",
      "0.9425398000740467\n",
      "0.9425398000740467\n",
      "0.9425398000740467\n",
      "0.9425398000740467\n",
      "0.9425398000740467\n",
      "0.9425398000740467\n",
      "0.9357089966679007\n",
      "0.5927064050351721\n",
      "0.5927064050351721\n",
      "0.5927064050351721\n",
      "0.522843391336542\n",
      "0.5022954461310626\n",
      "0.5022954461310626\n",
      "0.5022954461310626\n",
      "0.5022954461310626\n",
      "0.2621251388374676\n",
      "0.2552943354313217\n",
      "0.24433543132173266\n",
      "0.24433543132173266\n",
      "0.24433543132173266\n",
      "0.24433543132173266\n",
      "0.24433543132173266\n",
      "0.232006664198445\n",
      "0.14315068493150684\n",
      "0.14315068493150684\n",
      "0.14315068493150684\n",
      "0.128156238430211\n",
      "0.128156238430211\n",
      "0.128156238430211\n",
      "0.128156238430211\n",
      "0.09544613106256941\n",
      "0.08861532765642355\n",
      "0.08861532765642355\n",
      "0.08861532765642355\n",
      "0.08861532765642355\n",
      "0.08861532765642355\n",
      "0.08045168456127359\n",
      "0.08045168456127359\n",
      "0.08045168456127359\n",
      "0.06956682710107367\n",
      "0.054572380599777856\n",
      "0.054572380599777856\n",
      "0.054572380599777856\n",
      "0.054572380599777856\n",
      "0.054572380599777856\n",
      "0.054572380599777856\n",
      "0.054572380599777856\n",
      "0.054572380599777856\n",
      "0.054572380599777856\n",
      "0.046390225842280634\n",
      "0.046390225842280634\n",
      "0.046390225842280634\n",
      "0.046390225842280634\n",
      "0.046390225842280634\n",
      "0.046390225842280634\n",
      "0.046390225842280634\n",
      "0.046390225842280634\n",
      "0.046390225842280634\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "find_recall_threshold(decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores\n",
      "Accuracy: 0.5413680781758957\n",
      "Recall: 0.97632058287796\n",
      "Specificity: 0.29918864097363085\n",
      "Precision: 0.43683781581092096\n",
      "F1: 0.6036036036036037\n",
      "ROC AUC: 0.7536559187458665\n",
      "--------------------------------\n",
      "Test Scores\n",
      "Accuracy: 0.44140625\n",
      "Recall: 0.8032786885245902\n",
      "Specificity: 0.24012158054711247\n",
      "Precision: 0.3702770780856423\n",
      "F1: 0.506896551724138\n",
      "ROC AUC: 0.5612304217117611\n",
      "0.4414\t0.8033\t0.2401\t0.3703\t0.5069\t0.5612\n"
     ]
    }
   ],
   "source": [
    "using_recall_threshold(decision_tree, 0.39795918367346933)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time\n",
      "0.0009387016296386718\n",
      "score_time\n",
      "0.007428741455078125\n",
      "test_acc\n",
      "0.5179271708683473\n",
      "test_rec\n",
      "0.9726599326599328\n",
      "test_spec\n",
      "0.2647186147186147\n",
      "test_prec\n",
      "0.4250003580723882\n",
      "test_f1_score\n",
      "0.5911953502356774\n",
      "test_auc\n",
      "0.7036059974443812\n"
     ]
    }
   ],
   "source": [
    "cross_validated_threshold(decision_tree, 0.39795918367346933)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "class_weight: balanced, criterion: gini, max_depth: 4, n_estimators: 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(\n",
    "    class_weight='balanced',\n",
    "    criterion='gini',\n",
    "    max_depth=4,\n",
    "    n_estimators=250\n",
    ").fit(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores\n",
      "Accuracy: 0.6671009771986971\n",
      "Recall: 0.7340619307832422\n",
      "Specificity: 0.6298174442190669\n",
      "Precision: 0.5247395833333334\n",
      "F1: 0.6119969627942293\n",
      "ROC AUC: 0.6819396875011545\n",
      "--------------------------------\n",
      "Test Scores\n",
      "Accuracy: 0.603515625\n",
      "Recall: 0.6284153005464481\n",
      "Specificity: 0.5896656534954408\n",
      "Precision: 0.46\n",
      "F1: 0.5311778290993071\n",
      "ROC AUC: 0.6090404770209444\n",
      "0.6035, 0.6284, 0.5897, 0.4600, 0.5312, 0.6090\n"
     ]
    }
   ],
   "source": [
    "print_scoring_metrics(random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{np.float64(0.4387755102040816): 0.8032786885245902}\n"
     ]
    }
   ],
   "source": [
    "find_recall_threshold(random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores\n",
      "Accuracy: 0.5641693811074918\n",
      "Recall: 0.8652094717668488\n",
      "Specificity: 0.39655172413793105\n",
      "Precision: 0.4439252336448598\n",
      "F1: 0.586781964175417\n",
      "ROC AUC: 0.7416813531517751\n",
      "--------------------------------\n",
      "Test Scores\n",
      "Accuracy: 0.51953125\n",
      "Recall: 0.8032786885245902\n",
      "Specificity: 0.3617021276595745\n",
      "Precision: 0.4117647058823529\n",
      "F1: 0.5444444444444444\n",
      "ROC AUC: 0.6397096683109939\n",
      "0.5195\t0.8033\t0.3617\t0.4118\t0.5444\t0.6397\n"
     ]
    }
   ],
   "source": [
    "using_recall_threshold(random_forest, 0.4387755102040816)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN\n",
    "\n",
    "n_neighbors: 99, weights: uniform, p: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(\n",
    "    n_neighbors=3\n",
    ").fit(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores\n",
      "Accuracy: 0.7993485342019544\n",
      "Recall: 0.6211293260473588\n",
      "Specificity: 0.8985801217038539\n",
      "Precision: 0.7732426303854876\n",
      "F1: 0.6888888888888889\n",
      "ROC AUC: 0.8599592842601521\n",
      "--------------------------------\n",
      "Test Scores\n",
      "Accuracy: 0.58984375\n",
      "Recall: 0.31693989071038253\n",
      "Specificity: 0.7416413373860182\n",
      "Precision: 0.40559440559440557\n",
      "F1: 0.3558282208588957\n",
      "ROC AUC: 0.5610228046572657\n",
      "0.5898\t0.3169\t0.7416\t0.4056\t0.3558\t0.5610\n"
     ]
    }
   ],
   "source": [
    "print_scoring_metrics(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{np.float64(0.01020408163265306): 0.7868852459016393, np.float64(0.02040816326530612): 0.7868852459016393, np.float64(0.030612244897959183): 0.7868852459016393, np.float64(0.04081632653061224): 0.7868852459016393, np.float64(0.0510204081632653): 0.7868852459016393, np.float64(0.061224489795918366): 0.7868852459016393, np.float64(0.07142857142857142): 0.7868852459016393, np.float64(0.08163265306122448): 0.7868852459016393, np.float64(0.09183673469387754): 0.7868852459016393, np.float64(0.1020408163265306): 0.7868852459016393, np.float64(0.11224489795918366): 0.7868852459016393, np.float64(0.12244897959183673): 0.7868852459016393, np.float64(0.13265306122448978): 0.7868852459016393, np.float64(0.14285714285714285): 0.7868852459016393, np.float64(0.1530612244897959): 0.7868852459016393, np.float64(0.16326530612244897): 0.7868852459016393, np.float64(0.17346938775510204): 0.7868852459016393, np.float64(0.18367346938775508): 0.7868852459016393, np.float64(0.19387755102040816): 0.7868852459016393, np.float64(0.2040816326530612): 0.7868852459016393, np.float64(0.21428571428571427): 0.7868852459016393, np.float64(0.22448979591836732): 0.7868852459016393, np.float64(0.2346938775510204): 0.7868852459016393, np.float64(0.24489795918367346): 0.7868852459016393, np.float64(0.25510204081632654): 0.7868852459016393, np.float64(0.26530612244897955): 0.7868852459016393, np.float64(0.2755102040816326): 0.7868852459016393, np.float64(0.2857142857142857): 0.7868852459016393, np.float64(0.29591836734693877): 0.7868852459016393, np.float64(0.3061224489795918): 0.7868852459016393, np.float64(0.31632653061224486): 0.7868852459016393, np.float64(0.32653061224489793): 0.7868852459016393}\n"
     ]
    }
   ],
   "source": [
    "find_recall_threshold(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores\n",
      "Accuracy: 0.6651465798045603\n",
      "Recall: 1.0\n",
      "Specificity: 0.4787018255578093\n",
      "Precision: 0.5164628410159925\n",
      "F1: 0.6811414392059554\n",
      "ROC AUC: 0.8599592842601521\n",
      "--------------------------------\n",
      "Test Scores\n",
      "Accuracy: 0.486328125\n",
      "Recall: 0.7868852459016393\n",
      "Specificity: 0.3191489361702128\n",
      "Precision: 0.391304347826087\n",
      "F1: 0.5226860254083484\n",
      "ROC AUC: 0.5610228046572657\n",
      "0.4863\t0.7869\t0.3191\t0.3913\t0.5227\t0.5610\n"
     ]
    }
   ],
   "source": [
    "using_recall_threshold(knn, 0.32653061224489793)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "\n",
    "grow_policy: depthwise, max_depth: 2, n_estimators: 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    grow_policy = 'depthwise',\n",
    "    max_depth = 2,\n",
    "    n_estimators = 150\n",
    ").fit(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores\n",
      "Accuracy: 0.7713355048859935\n",
      "Recall: 0.5373406193078324\n",
      "Specificity: 0.9016227180527383\n",
      "Precision: 0.7525510204081632\n",
      "F1: 0.6269925611052072\n",
      "ROC AUC: 0.8427234470196595\n",
      "--------------------------------\n",
      "Test Scores\n",
      "Accuracy: 0.626953125\n",
      "Recall: 0.3005464480874317\n",
      "Specificity: 0.8085106382978723\n",
      "Precision: 0.4661016949152542\n",
      "F1: 0.3654485049833887\n",
      "ROC AUC: 0.6213729300579667\n",
      "0.6270\t0.3005\t0.8085\t0.4661\t0.3654\t0.6214\n"
     ]
    }
   ],
   "source": [
    "print_scoring_metrics(xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2346938775510204\n",
      "Training Scores\n",
      "Accuracy: 0.6312703583061889\n",
      "Recall: 0.9435336976320583\n",
      "Specificity: 0.45740365111561865\n",
      "Precision: 0.4919278252611586\n",
      "F1: 0.6466916354556804\n",
      "ROC AUC: 0.7004686743738384\n",
      "--------------------------------\n",
      "Test Scores\n",
      "Accuracy: 0.537109375\n",
      "Recall: 0.7978142076502732\n",
      "Specificity: 0.39209726443769\n",
      "Precision: 0.42196531791907516\n",
      "F1: 0.5519848771266541\n",
      "ROC AUC: 0.5949557360439816\n",
      "0.5371\t0.7978\t0.3921\t0.4220\t0.5520\t0.5950\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_proba = xgb.predict_proba(XTrain)\n",
    "y_test_pred_proba = xgb.predict_proba(XTest)\n",
    "for threshold in np.linspace(0, 1, 99):\n",
    "    y_train_pred = (y_train_pred_proba[:, 1] >= threshold).astype(int)\n",
    "    y_test_pred = (y_test_pred_proba[:,1]>=threshold).astype(int)\n",
    "    if recall_score(yTest, y_test_pred) > 0.78 and recall_score(yTest, y_test_pred) < 0.80:\n",
    "        print(threshold)\n",
    "        print('Training Scores')\n",
    "        print(f'Accuracy: {accuracy_score(yTrain, y_train_pred)}')\n",
    "        print(f'Recall: {recall_score(yTrain, y_train_pred)}')\n",
    "        print(f'Specificity: {recall_score(yTrain, y_train_pred, pos_label=0)}')\n",
    "        print(f'Precision: {precision_score(yTrain, y_train_pred)}')\n",
    "        print(f'F1: {f1_score(yTrain, y_train_pred)}')\n",
    "        print(f'ROC AUC: {roc_auc_score(yTrain, y_train_pred)}')\n",
    "        print('--------------------------------')\n",
    "        print('Test Scores')\n",
    "        print(f'Accuracy: {accuracy_score(yTest, y_test_pred)}')\n",
    "        print(f'Recall: {recall_score(yTest, y_test_pred)}')\n",
    "        print(f'Specificity: {recall_score(yTest, y_test_pred, pos_label=0)}')\n",
    "        print(f'Precision: {precision_score(yTest, y_test_pred)}')\n",
    "        print(f'F1: {f1_score(yTest, y_test_pred)}')\n",
    "        print(f'ROC AUC: {roc_auc_score(yTest, y_test_pred)}')\n",
    "        print(f'{accuracy_score(yTest, y_test_pred):.4f}\\t{recall_score(yTest, y_test_pred):.4f}\\t{recall_score(yTest, y_test_pred, pos_label=0):.4f}\\t{precision_score(yTest, y_test_pred):.4f}\\t{f1_score(yTest, y_test_pred):.4f}\\t{roc_auc_score(yTest, y_test_pred):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = xgb.predict(XTrain)\n",
    "test_preds = xgb.predict_proba(XTest)\n",
    "print('Training Scores')\n",
    "print(f'Accuracy: {accuracy_score(yTrain, train_preds)}')\n",
    "print(f'Recall: {recall_score(yTrain, train_preds)}')\n",
    "print(f'Specificity: {recall_score(yTrain, train_preds, pos_label=0)}')\n",
    "print(f'Precision: {precision_score(yTrain, train_preds)}')\n",
    "print(f'F1: {f1_score(yTrain, train_preds)}')\n",
    "print(f'ROC AUC: {roc_auc_score(yTrain, train_preds)}')\n",
    "print('--------------------------------')\n",
    "print('Test Scores')\n",
    "print(f'Accuracy: {accuracy_score(yTest, test_preds)}')\n",
    "print(f'Recall: {recall_score(yTest, test_preds)}')\n",
    "print(f'Specificity: {recall_score(yTest, test_preds, pos_label=0)}')\n",
    "print(f'Precision: {precision_score(yTest, test_preds)}')\n",
    "print(f'F1: {f1_score(yTest, test_preds)}')\n",
    "print(f'ROC AUC: {roc_auc_score(yTest, test_preds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "nb = GaussianNB().fit(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores\n",
      "Accuracy: 0.43778501628664496\n",
      "Recall: 0.9617486338797814\n",
      "Specificity: 0.1460446247464503\n",
      "Precision: 0.3854014598540146\n",
      "F1: 0.5502866076081292\n",
      "ROC AUC: 0.6476351987940456\n",
      "--------------------------------\n",
      "Test Scores\n",
      "Accuracy: 0.439453125\n",
      "Recall: 0.9672131147540983\n",
      "Specificity: 0.1458966565349544\n",
      "Precision: 0.3864628820960699\n",
      "F1: 0.5522620904836193\n",
      "ROC AUC: 0.6206587273905029\n",
      "0.4395\t0.9672\t0.1459\t0.3865\t0.5523\t0.6207\n"
     ]
    }
   ],
   "source": [
    "print_scoring_metrics(nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "find_recall_threshold(nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9897959183673468\n",
      "0.8797814207650273\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = nb.predict_proba(XTest)\n",
    "for threshold in np.linspace(0, 1, 99):\n",
    "    y_pred = (y_pred_proba[:,1]>=threshold).astype(int)\n",
    "    if recall_score(yTest, y_pred) > 0.70 and recall_score(yTest, y_pred) < 0.89:\n",
    "        print(threshold)\n",
    "        print(recall_score(yTest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores\n",
      "Accuracy: 0.4762214983713355\n",
      "Recall: 0.9143897996357013\n",
      "Specificity: 0.23225152129817445\n",
      "Precision: 0.3987291501191422\n",
      "F1: 0.5553097345132744\n",
      "ROC AUC: 0.6476351987940456\n",
      "--------------------------------\n",
      "Test Scores\n",
      "Accuracy: 0.4609375\n",
      "Recall: 0.8797814207650273\n",
      "Specificity: 0.22796352583586627\n",
      "Precision: 0.38795180722891565\n",
      "F1: 0.5384615384615384\n",
      "ROC AUC: 0.6206587273905029\n",
      "0.4609\t0.8798\t0.2280\t0.3880\t0.5385\t0.6207\n"
     ]
    }
   ],
   "source": [
    "using_recall_threshold(nb, 0.9897959183673468)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores\n",
      "Accuracy: 0.6371335504885993\n",
      "Recall: 0.6939890710382514\n",
      "Specificity: 0.6054766734279919\n",
      "Precision: 0.4948051948051948\n",
      "F1: 0.577710386656558\n",
      "ROC AUC: 0.7107261219920417\n",
      "--------------------------------\n",
      "Test Scores\n",
      "Accuracy: 0.615234375\n",
      "Recall: 0.6284153005464481\n",
      "Specificity: 0.60790273556231\n",
      "Precision: 0.4713114754098361\n",
      "F1: 0.5386416861826698\n",
      "ROC AUC: 0.6645572773929943\n",
      "0.6152\t0.6284\t0.6079\t0.4713\t0.5386\t0.6646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ben\\MS Classification Research\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "log_reg = LogisticRegression(\n",
    "    max_iter=500,\n",
    "    class_weight='balanced'\n",
    ").fit(XTrain, yTrain)\n",
    "\n",
    "print_scoring_metrics(log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{np.float64(0.3877551020408163): 0.8142076502732241, np.float64(0.39795918367346933): 0.8032786885245902, np.float64(0.4081632653061224): 0.7923497267759563}\n"
     ]
    }
   ],
   "source": [
    "find_recall_threshold(log_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores\n",
      "Accuracy: 0.5811074918566775\n",
      "Recall: 0.8451730418943534\n",
      "Specificity: 0.4340770791075051\n",
      "Precision: 0.45401174168297453\n",
      "F1: 0.5907065563335455\n",
      "ROC AUC: 0.7107261219920417\n",
      "--------------------------------\n",
      "Test Scores\n",
      "Accuracy: 0.55859375\n",
      "Recall: 0.7923497267759563\n",
      "Specificity: 0.42857142857142855\n",
      "Precision: 0.43543543543543545\n",
      "F1: 0.562015503875969\n",
      "ROC AUC: 0.6645572773929943\n",
      "0.5586\t0.7923\t0.4286\t0.4354\t0.5620\t0.6646\n"
     ]
    }
   ],
   "source": [
    "using_recall_threshold(log_reg, 0.4081632653061224)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
